import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import TextVectorization
import nltk
from nltk.corpus import stopwords
import nltk
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report,confusion_matrix

# Streamlit input
text_to_predict = st.text_input("Enter the text to predict:")

# Download stopwords
nltk.download('stopwords', quiet=True)
stop_words = set(stopwords.words('english'))



if text_to_predict:

    # Remove stopwords
    text_to_predict = ' '.join([word for word in text_to_predict.split() if word.lower() not in stop_words])

    # Load vectorizer
    vectorized_layer=tf.keras.layers.TextVectorization(ragged=True,max_tokens=20000)
    # vectorized_layer.adapt(text_to_predict)

    sequence = vectorized_layer([text_to_predict])
    padded_sequence = tf.keras.utils.pad_sequences(
        sequence.numpy(),
        maxlen=50,
        padding='pre',
        truncating='pre'
    )

    # Load AI detector model
    model = load_model("model_ai_detector.h5")

    # Make prediction
    prediction = model.predict(padded_sequence)

    # Display result
    if prediction[0][0] > 0.5:
        st.markdown("<h3>Your text is generated by AI</h3>", unsafe_allow_html=True)
    else:
        st.markdown("<h3>Your text is generated by Human</h3>", unsafe_allow_html=True)
